{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgvxI982/bxWj1D0/PREKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itskutush/Attention-based-automated-radiology-report-generation/blob/main/Transformer%20NMT%20with%20Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "F4K0QnYbM0rh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/translated_output.csv\")"
      ],
      "metadata": {
        "id": "tNDC-FcJNDoT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna().reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "d9ptvLhdN3OA",
        "outputId": "f02a1f02-9450-4bc9-fee9-79e7b829739d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               findings  \\\n",
              "0     The cardiac silhouette and mediastinum size ar...   \n",
              "1     Borderline cardiomegaly. Midline sternotomy XX...   \n",
              "2     There are diffuse bilateral interstitial and a...   \n",
              "3     The cardiomediastinal silhouette and pulmonary...   \n",
              "4     Heart size and mediastinal contour are within ...   \n",
              "...                                                 ...   \n",
              "3332  The heart is mildly enlarged. Left hemidiaphra...   \n",
              "3333  Similar mild cardiomegaly. Of the pulmonary va...   \n",
              "3334  The cardiomediastinal silhouette and pulmonary...   \n",
              "3335  The lungs are clear. Heart size is normal. No ...   \n",
              "3336  Heart size within normal limits. Small, nodula...   \n",
              "\n",
              "                                    findings_translated  \n",
              "0     कार्डियक सिल्हूट और मीडियास्टिनम का आकार सामान...  \n",
              "1     बॉर्डरलाइन कार्डियोमेगाली.मिडलाइन स्टर्नोटॉमी ...  \n",
              "2     क्रोनिक ऑब्सट्रक्टिव फेफड़े की बीमारी और बुलस ...  \n",
              "3     कार्डियोमीडियास्टिनल सिल्हूट और फुफ्फुसीय वाहि...  \n",
              "4     हृदय का आकार और मीडियास्टीनल रूपरेखा सामान्य स...  \n",
              "...                                                 ...  \n",
              "3332  हृदय हल्का सा बड़ा हो गया है।बायां हेमिडियाफ्र...  \n",
              "3333  समान हल्का कार्डियोमेगाली।फुफ्फुसीय संवहनीकरण ...  \n",
              "3334  कार्डियोमीडियास्टिनल सिल्हूट और फुफ्फुसीय वाहि...  \n",
              "3335  फेफड़े साफ हैं.हृदय का आकार सामान्य है.कोई न्य...  \n",
              "3336  हृदय का आकार सामान्य सीमा के भीतर।दाहिने ऊपरी ...  \n",
              "\n",
              "[3337 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51608de2-5a9e-481f-8756-e188b4971958\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>findings</th>\n",
              "      <th>findings_translated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
              "      <td>कार्डियक सिल्हूट और मीडियास्टिनम का आकार सामान...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
              "      <td>बॉर्डरलाइन कार्डियोमेगाली.मिडलाइन स्टर्नोटॉमी ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There are diffuse bilateral interstitial and a...</td>\n",
              "      <td>क्रोनिक ऑब्सट्रक्टिव फेफड़े की बीमारी और बुलस ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The cardiomediastinal silhouette and pulmonary...</td>\n",
              "      <td>कार्डियोमीडियास्टिनल सिल्हूट और फुफ्फुसीय वाहि...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Heart size and mediastinal contour are within ...</td>\n",
              "      <td>हृदय का आकार और मीडियास्टीनल रूपरेखा सामान्य स...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>The heart is mildly enlarged. Left hemidiaphra...</td>\n",
              "      <td>हृदय हल्का सा बड़ा हो गया है।बायां हेमिडियाफ्र...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3333</th>\n",
              "      <td>Similar mild cardiomegaly. Of the pulmonary va...</td>\n",
              "      <td>समान हल्का कार्डियोमेगाली।फुफ्फुसीय संवहनीकरण ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3334</th>\n",
              "      <td>The cardiomediastinal silhouette and pulmonary...</td>\n",
              "      <td>कार्डियोमीडियास्टिनल सिल्हूट और फुफ्फुसीय वाहि...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3335</th>\n",
              "      <td>The lungs are clear. Heart size is normal. No ...</td>\n",
              "      <td>फेफड़े साफ हैं.हृदय का आकार सामान्य है.कोई न्य...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3336</th>\n",
              "      <td>Heart size within normal limits. Small, nodula...</td>\n",
              "      <td>हृदय का आकार सामान्य सीमा के भीतर।दाहिने ऊपरी ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3337 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51608de2-5a9e-481f-8756-e188b4971958')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51608de2-5a9e-481f-8756-e188b4971958 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51608de2-5a9e-481f-8756-e188b4971958');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c8accc6-ba28-494a-afa7-3e2fe8913687\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c8accc6-ba28-494a-afa7-3e2fe8913687')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c8accc6-ba28-494a-afa7-3e2fe8913687 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fbab7dff-dc41-482a-aacb-08e475f4defe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbab7dff-dc41-482a-aacb-08e475f4defe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3337,\n  \"fields\": [\n    {\n      \"column\": \"findings\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2553,\n        \"samples\": [\n          \"The cardiac silhouette is mildly enlarged and appears mildly increased in size from the XXXX study. There is normal caliber pulmonary vasculature. The lungs are grossly clear of focal airspace disease, pneumothorax, or pleural effusion. There is no evidence of pulmonary edema.\",\n          \"Cardiac and mediastinal contours are within normal limits. Prior granulomatous disease. The lungs are clear. Bony structures are intact.\",\n          \"Heart size normal. No pneumothorax, pleural effusion, or focal airspace disease. Bony structures appear intact. The trachea and XXXX pulmonary bronchi are unremarkable.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"findings_translated\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2536,\n        \"samples\": [\n          \"\\u092c\\u093e\\u0907\\u092c\\u0947\\u0938\\u093f\\u0932\\u0930 \\u0938\\u092c\\u0938\\u0947\\u0917\\u094d\\u092e\\u0947\\u0902\\u091f\\u0932 \\u090f\\u091f\\u0947\\u0932\\u0947\\u0915\\u094d\\u091f\\u0948\\u0938\\u093f\\u0938 \\u0915\\u0947 \\u0938\\u093e\\u0925 \\u092b\\u0947\\u092b\\u0921\\u093c\\u094b\\u0902 \\u0915\\u0940 \\u0915\\u092e \\u092e\\u093e\\u0924\\u094d\\u0930\\u093e\\u0964\\u0915\\u094b\\u0908 \\u092b\\u094b\\u0915\\u0932 \\u0938\\u092e\\u0947\\u0915\\u0928, \\u092b\\u0941\\u092b\\u094d\\u092b\\u0941\\u0938 \\u092c\\u0939\\u093e\\u0935 \\u092f\\u093e \\u0928\\u094d\\u092f\\u0942\\u092e\\u094b\\u0925\\u094b\\u0930\\u0947\\u0938 \\u0928\\u0939\\u0940\\u0902\\u0964\\u0915\\u093e\\u0930\\u094d\\u0921\\u093f\\u092f\\u094b\\u092e\\u0940\\u0921\\u093f\\u092f\\u093e\\u0938\\u094d\\u091f\\u093f\\u0928\\u0932 \\u0938\\u093f\\u0932\\u094d\\u0939\\u0942\\u091f \\u0938\\u093e\\u092e\\u093e\\u0928\\u094d\\u092f \\u0938\\u0940\\u092e\\u093e \\u0915\\u0947 \\u092d\\u0940\\u0924\\u0930 \\u0939\\u0948\\u0964\\u0935\\u0915\\u094d\\u0937\\u0940\\u092f \\u0930\\u0940\\u0922\\u093c \\u092e\\u0947\\u0902 \\u0905\\u092a\\u0915\\u094d\\u0937\\u092f\\u0940 \\u092a\\u0930\\u093f\\u0935\\u0930\\u094d\\u0924\\u0928\\u0964\",\n          \"\\u0915\\u093e\\u0930\\u094d\\u0921\\u093f\\u092f\\u094b\\u092e\\u0940\\u0921\\u093f\\u092f\\u093e\\u0938\\u094d\\u091f\\u093f\\u0928\\u0932 \\u0938\\u093f\\u0932\\u094d\\u0939\\u0942\\u091f \\u0938\\u093e\\u092e\\u093e\\u0928\\u094d\\u092f \\u0938\\u0940\\u092e\\u093e \\u0915\\u0947 \\u092d\\u0940\\u0924\\u0930 \\u0939\\u0948\\u0964\\u0915\\u094b\\u0908 \\u092b\\u094b\\u0915\\u0932 \\u0938\\u092e\\u0947\\u0915\\u0928 \\u0928\\u0939\\u0940\\u0902.\\u0915\\u094b\\u0908 \\u0928\\u094d\\u092f\\u0942\\u092e\\u094b\\u0925\\u094b\\u0930\\u0948\\u0915\\u094d\\u0938 \\u092f\\u093e \\u092b\\u0941\\u092b\\u094d\\u092b\\u0941\\u0938 \\u092c\\u0939\\u093e\\u0935 \\u0928\\u0939\\u0940\\u0902\\u0964\\u0915\\u094b\\u0908 \\u0924\\u0940\\u0935\\u094d\\u0930 \\u0939\\u0921\\u094d\\u0921\\u0940 \\u0938\\u0902\\u092c\\u0902\\u0927\\u0940 \\u0905\\u0938\\u093e\\u092e\\u093e\\u0928\\u094d\\u092f\\u0924\\u093e\\u090f\\u0902 \\u0928\\u0939\\u0940\\u0902\\u0964\",\n          \"\\u092b\\u0947\\u092b\\u0921\\u093c\\u0947 \\u0938\\u093e\\u092b \\u0926\\u093f\\u0916\\u093e\\u0908 \\u0926\\u0947\\u0924\\u0947 \\u0939\\u0948\\u0902\\u0964\\u0939\\u0943\\u0926\\u092f \\u0914\\u0930 \\u092b\\u0941\\u092b\\u094d\\u092b\\u0941\\u0938\\u0940\\u092f XXXX \\u0938\\u093e\\u092e\\u093e\\u0928\\u094d\\u092f \\u0939\\u0948\\u0902\\u0964\\u092b\\u0941\\u092b\\u094d\\u092b\\u0941\\u0938 \\u0938\\u094d\\u0925\\u093e\\u0928 \\u0938\\u094d\\u092a\\u0937\\u094d\\u091f \\u0939\\u0948\\u0902\\u0964\\u092e\\u0940\\u0921\\u093f\\u092f\\u093e\\u0938\\u094d\\u091f\\u093f\\u0928\\u0932 \\u0906\\u0915\\u0943\\u0924\\u093f\\u092f\\u093e\\u0901 \\u0938\\u093e\\u092e\\u093e\\u0928\\u094d\\u092f \\u0939\\u0948\\u0902\\u0964XXXX \\u0938\\u094d\\u091f\\u0930\\u094d\\u0928\\u094b\\u091f\\u0949\\u092e\\u0940 \\u0914\\u0930 \\u0938\\u0940\\u090f\\u092c\\u0940\\u091c\\u0940 \\u0915\\u0947 \\u092c\\u093e\\u0926 \\u0930\\u094b\\u0917\\u0940 \\u0915\\u0940 \\u0938\\u094d\\u0925\\u093f\\u0924\\u093f\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Optional BLEU score evaluation\n",
        "try:\n",
        "    import nltk\n",
        "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "    nltk.download('punkt')\n",
        "    # Download punkt_tab resource for sentence_bleu\n",
        "    nltk.download('punkt_tab')\n",
        "    HAVE_NLTK = True\n",
        "except Exception:\n",
        "    HAVE_NLTK = False\n",
        "\n",
        "# -------------------------\n",
        "# 1) Hyperparameters\n",
        "# -------------------------\n",
        "CSV_PATH = \"./translated_output.csv\"  # Adjust path as needed\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 256\n",
        "NUM_HEADS = 8\n",
        "NUM_LAYERS = 4\n",
        "DFF = 512  # Feed-forward dimension\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 50\n",
        "MAX_VOCAB_SIZE = None  # None = keep all words; set int to limit\n",
        "SAVE_DIR = \"./transformer_weights\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -------------------------\n",
        "# 2) Preprocess utility\n",
        "# -------------------------\n",
        "def preprocess_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = \"\"\n",
        "    return s.strip().lower()\n",
        "\n",
        "# -------------------------\n",
        "# 3) Load and prepare data\n",
        "# -------------------------\n",
        "def load_data(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = df.dropna(subset=['findings', 'findings_translated']).reset_index(drop=True)\n",
        "    df['eng'] = df['findings'].astype(str).apply(preprocess_text)\n",
        "    df['hin'] = df['findings_translated'].astype(str).apply(lambda x: f\"<start> {x.strip()} <end>\")\n",
        "    return df['eng'].tolist(), df['hin'].tolist(), df\n",
        "\n",
        "eng_texts, hin_texts, df = load_data(CSV_PATH)\n",
        "\n",
        "# -------------------------\n",
        "# 4) Tokenizers\n",
        "# -------------------------\n",
        "class Tokenizer:\n",
        "    def __init__(self, texts, max_vocab_size=None):\n",
        "        self.word2idx = {\"<pad>\": 0, \"<unk>\": 1}\n",
        "        self.idx2word = {0: \"<pad>\", 1: \"<unk>\"}\n",
        "        word_counts = Counter()\n",
        "        for text in texts:\n",
        "            words = text.split()\n",
        "            word_counts.update(words)\n",
        "\n",
        "        # Build vocabulary\n",
        "        vocab = [word for word, _ in word_counts.most_common(max_vocab_size)]\n",
        "        for i, word in enumerate(vocab, start=2):\n",
        "            self.word2idx[word] = i\n",
        "            self.idx2word[i] = word\n",
        "\n",
        "    def encode(self, text):\n",
        "        return [self.word2idx.get(word, self.word2idx[\"<unk>\"]) for word in text.split()]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return \" \".join(self.idx2word.get(idx, \"<unk>\") for idx in indices if idx != 0)\n",
        "\n",
        "    def vocab_size(self):\n",
        "        return len(self.word2idx)\n",
        "\n",
        "eng_tokenizer = Tokenizer(eng_texts, MAX_VOCAB_SIZE)\n",
        "hin_tokenizer = Tokenizer(hin_texts, MAX_VOCAB_SIZE)\n",
        "\n",
        "if \"<start>\" not in hin_tokenizer.word2idx or \"<end>\" not in hin_tokenizer.word2idx:\n",
        "    raise ValueError(\"Hindi tokenizer missing <start> or <end> tokens\")\n",
        "\n",
        "# -------------------------\n",
        "# 5) Dataset and DataLoader\n",
        "# -------------------------\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, eng_texts, hin_texts, eng_tokenizer, hin_tokenizer):\n",
        "        self.eng_texts = eng_texts\n",
        "        self.hin_texts = hin_texts\n",
        "        self.eng_tokenizer = eng_tokenizer\n",
        "        self.hin_tokenizer = hin_tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eng_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        eng = self.eng_tokenizer.encode(self.eng_texts[idx])\n",
        "        hin = self.hin_tokenizer.encode(self.hin_texts[idx])\n",
        "        return torch.tensor(eng, dtype=torch.long), torch.tensor(hin, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    eng_batch, hin_batch = zip(*batch)\n",
        "    eng_batch = pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
        "    hin_batch = pad_sequence(hin_batch, batch_first=True, padding_value=0)\n",
        "    hin_input = hin_batch[:, :-1]  # Decoder input (without <end>)\n",
        "    hin_target = hin_batch[:, 1:]  # Decoder target (without <start>)\n",
        "    return eng_batch, hin_input, hin_target\n",
        "\n",
        "dataset = TranslationDataset(eng_texts, hin_texts, eng_tokenizer, hin_tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "steps_per_epoch = len(dataset) // BATCH_SIZE\n",
        "\n",
        "# -------------------------\n",
        "# 6) Transformer Model\n",
        "# -------------------------\n",
        "class TransformerNMT(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, dff, max_seq_len, dropout=0.1):\n",
        "        super(TransformerNMT, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_encoding = self.positional_encoding(max_seq_len, d_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=dff,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.d_model = d_model\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def positional_encoding(self, max_len, d_model):\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        return pe.unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n",
        "        src = self.src_embedding(src) * np.sqrt(self.d_model)\n",
        "        src = src + self.pos_encoding[:, :src.size(1), :].to(DEVICE)\n",
        "        src = self.dropout(src)\n",
        "\n",
        "        tgt = self.tgt_embedding(tgt) * np.sqrt(self.d_model)\n",
        "        tgt = tgt + self.pos_encoding[:, :tgt.size(1), :].to(DEVICE)\n",
        "        tgt = self.dropout(tgt)\n",
        "\n",
        "        output = self.transformer(\n",
        "            src, tgt,\n",
        "            src_mask=src_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=src_padding_mask\n",
        "        )\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "\n",
        "# -------------------------\n",
        "# 7) Masking\n",
        "# -------------------------\n",
        "def create_padding_mask(seq):\n",
        "    return (seq == 0).to(DEVICE)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
        "    return mask.to(DEVICE)\n",
        "\n",
        "# -------------------------\n",
        "# 8) Instantiate model\n",
        "# -------------------------\n",
        "max_len = max(max(len(eng_tokenizer.encode(t)) for t in eng_texts),\n",
        "              max(len(hin_tokenizer.encode(t)) for t in hin_texts))\n",
        "model = TransformerNMT(\n",
        "    src_vocab_size=eng_tokenizer.vocab_size(),\n",
        "    tgt_vocab_size=hin_tokenizer.vocab_size(),\n",
        "    d_model=EMBEDDING_DIM,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dff=DFF,\n",
        "    max_seq_len=max_len,\n",
        "    dropout=DROPOUT\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "\n",
        "# -------------------------\n",
        "# 9) Training loop\n",
        "# -------------------------\n",
        "def train_step(model, src, tgt_input, tgt_target):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    src_padding_mask = create_padding_mask(src)\n",
        "    tgt_padding_mask = create_padding_mask(tgt_input)\n",
        "    tgt_mask = create_look_ahead_mask(tgt_input.size(1))\n",
        "\n",
        "    output = model(src, tgt_input,\n",
        "                   tgt_mask=tgt_mask,\n",
        "                   src_padding_mask=src_padding_mask,\n",
        "                   tgt_padding_mask=tgt_padding_mask)\n",
        "\n",
        "    loss = criterion(output.view(-1, output.size(-1)), tgt_target.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0.0\n",
        "    prog = tqdm(enumerate(dataloader), total=steps_per_epoch, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for i, (src, tgt_input, tgt_target) in prog:\n",
        "        if i >= steps_per_epoch:\n",
        "            break\n",
        "        src, tgt_input, tgt_target = src.to(DEVICE), tgt_input.to(DEVICE), tgt_target.to(DEVICE)\n",
        "        loss = train_step(model, src, tgt_input, tgt_target)\n",
        "        total_loss += loss\n",
        "        if (i + 1) % 50 == 0:\n",
        "            prog.set_postfix({'batch_loss': loss})\n",
        "    epoch_loss = total_loss / steps_per_epoch\n",
        "    print(f\"\\nEpoch {epoch+1} Loss {epoch_loss:.4f}\")\n",
        "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, f\"transformer_epoch{epoch+1}.pth\"))\n",
        "\n",
        "# -------------------------\n",
        "# 10) Inference\n",
        "# -------------------------\n",
        "def evaluate(sentence, max_len_out=max_len):\n",
        "    model.eval()\n",
        "    sentence = preprocess_text(sentence)\n",
        "    src = torch.tensor([eng_tokenizer.encode(sentence)], dtype=torch.long).to(DEVICE)\n",
        "    src = pad_sequence([src[0]], batch_first=True, padding_value=0).to(DEVICE)\n",
        "\n",
        "    tgt = torch.tensor([[hin_tokenizer.word2idx[\"<start>\"]]], dtype=torch.long).to(DEVICE)\n",
        "    output_tokens = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len_out):\n",
        "            src_padding_mask = create_padding_mask(src)\n",
        "            tgt_padding_mask = create_padding_mask(tgt)\n",
        "            tgt_mask = create_look_ahead_mask(tgt.size(1))\n",
        "\n",
        "            output = model(src, tgt,\n",
        "                          tgt_mask=tgt_mask,\n",
        "                          src_padding_mask=src_padding_mask,\n",
        "                          tgt_padding_mask=tgt_padding_mask)\n",
        "\n",
        "            predicted_id = torch.argmax(output[:, -1, :], dim=-1).item()\n",
        "            if predicted_id == hin_tokenizer.word2idx[\"<end>\"]:\n",
        "                break\n",
        "            output_tokens.append(predicted_id)\n",
        "            tgt = torch.cat([tgt, torch.tensor([[predicted_id]], dtype=torch.long).to(DEVICE)], dim=1)\n",
        "\n",
        "    return hin_tokenizer.decode(output_tokens)\n",
        "\n",
        "def translate(sentence):\n",
        "    return evaluate(sentence)\n",
        "\n",
        "# -------------------------\n",
        "# 11) Test translations\n",
        "# -------------------------\n",
        "examples = [\n",
        "    \"Borderline cardiomegaly. Midline sternotomy noted.\",\n",
        "    \"The cardiac silhouette and mediastinum size are within normal limits.\"\n",
        "]\n",
        "for ex in examples:\n",
        "    print(\"ENG:\", ex)\n",
        "    print(\"HIN:\", translate(ex))\n",
        "    print()\n",
        "\n",
        "# -------------------------\n",
        "# 12) BLEU evaluation\n",
        "# -------------------------\n",
        "if HAVE_NLTK:\n",
        "    smooth = SmoothingFunction().method1\n",
        "    n_samples = min(50, len(df))\n",
        "    refs = []\n",
        "    hyps = []\n",
        "    for i in range(n_samples):\n",
        "        cand = translate(df['eng'].iloc[i])\n",
        "        ref = df['hin'].iloc[i].replace('<start>', '').replace('<end>', '').strip()\n",
        "        ref_tok = nltk.word_tokenize(ref)\n",
        "        cand_tok = nltk.word_tokenize(cand)\n",
        "        refs.append([ref_tok])\n",
        "        hyps.append(cand_tok)\n",
        "    bleu_scores = [sentence_bleu(refs[i], hyps[i], smoothing_function=smooth) for i in range(len(hyps))]\n",
        "    print(\"Avg sentence BLEU (sample):\", np.mean(bleu_scores))\n",
        "else:\n",
        "    print(\"nltk not available. Skip BLEU.\")\n",
        "\n",
        "# -------------------------\n",
        "# 13) Save tokenizers\n",
        "# -------------------------\n",
        "with open(os.path.join(SAVE_DIR, \"eng_tokenizer.json\"), \"w\", encoding='utf-8') as f:\n",
        "    json.dump({\"word2idx\": eng_tokenizer.word2idx, \"idx2word\": eng_tokenizer.idx2word}, f)\n",
        "with open(os.path.join(SAVE_DIR, \"hin_tokenizer.json\"), \"w\", encoding='utf-8') as f:\n",
        "    json.dump({\"word2idx\": hin_tokenizer.word2idx, \"idx2word\": hin_tokenizer.idx2word}, f)\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvPhnPgFayQd",
        "outputId": "bb82f96a-8f7a-437e-a066-e2c7a34f1575"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Epoch 1/50: 100%|██████████| 104/104 [00:06<00:00, 15.98it/s, batch_loss=5.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Loss 6.6586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 104/104 [00:06<00:00, 15.75it/s, batch_loss=4.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Loss 4.9714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 104/104 [00:06<00:00, 16.28it/s, batch_loss=4.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 Loss 4.2926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 104/104 [00:06<00:00, 15.77it/s, batch_loss=3.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Loss 3.8422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 104/104 [00:06<00:00, 15.57it/s, batch_loss=2.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Loss 3.5247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 104/104 [00:06<00:00, 15.55it/s, batch_loss=3.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 Loss 3.2712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 104/104 [00:06<00:00, 15.66it/s, batch_loss=3.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 Loss 3.0676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 104/104 [00:06<00:00, 16.20it/s, batch_loss=3.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 Loss 2.8996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 104/104 [00:06<00:00, 16.08it/s, batch_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 Loss 2.7567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 104/104 [00:06<00:00, 16.43it/s, batch_loss=2.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 Loss 2.6325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 104/104 [00:06<00:00, 16.17it/s, batch_loss=2.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 Loss 2.5258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 104/104 [00:06<00:00, 16.40it/s, batch_loss=2.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 Loss 2.4324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 104/104 [00:06<00:00, 16.14it/s, batch_loss=2.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 Loss 2.3419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|██████████| 104/104 [00:06<00:00, 16.30it/s, batch_loss=2.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 Loss 2.2697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|██████████| 104/104 [00:06<00:00, 15.96it/s, batch_loss=2.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 Loss 2.1923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|██████████| 104/104 [00:06<00:00, 16.32it/s, batch_loss=2.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16 Loss 2.1269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|██████████| 104/104 [00:06<00:00, 16.02it/s, batch_loss=2.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17 Loss 2.0662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|██████████| 104/104 [00:06<00:00, 16.33it/s, batch_loss=1.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18 Loss 2.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|██████████| 104/104 [00:06<00:00, 15.98it/s, batch_loss=1.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19 Loss 1.9584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|██████████| 104/104 [00:06<00:00, 16.37it/s, batch_loss=1.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20 Loss 1.9006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|██████████| 104/104 [00:06<00:00, 16.18it/s, batch_loss=1.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21 Loss 1.8515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|██████████| 104/104 [00:06<00:00, 16.10it/s, batch_loss=1.96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22 Loss 1.8061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|██████████| 104/104 [00:06<00:00, 16.23it/s, batch_loss=1.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23 Loss 1.7650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|██████████| 104/104 [00:06<00:00, 15.89it/s, batch_loss=1.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24 Loss 1.7199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|██████████| 104/104 [00:06<00:00, 16.33it/s, batch_loss=2.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25 Loss 1.6786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|██████████| 104/104 [00:06<00:00, 15.80it/s, batch_loss=1.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 26 Loss 1.6352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|██████████| 104/104 [00:06<00:00, 16.10it/s, batch_loss=1.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 27 Loss 1.5950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|██████████| 104/104 [00:06<00:00, 15.83it/s, batch_loss=1.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 28 Loss 1.5596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|██████████| 104/104 [00:06<00:00, 16.31it/s, batch_loss=1.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 29 Loss 1.5258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|██████████| 104/104 [00:06<00:00, 15.84it/s, batch_loss=1.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30 Loss 1.4911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|██████████| 104/104 [00:06<00:00, 16.62it/s, batch_loss=1.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 31 Loss 1.4533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|██████████| 104/104 [00:06<00:00, 16.07it/s, batch_loss=1.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 32 Loss 1.4246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|██████████| 104/104 [00:06<00:00, 16.21it/s, batch_loss=1.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 33 Loss 1.3881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|██████████| 104/104 [00:06<00:00, 16.07it/s, batch_loss=0.978]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 34 Loss 1.3559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|██████████| 104/104 [00:06<00:00, 16.26it/s, batch_loss=1.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 35 Loss 1.3255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|██████████| 104/104 [00:06<00:00, 15.98it/s, batch_loss=1.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 36 Loss 1.2984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|██████████| 104/104 [00:06<00:00, 16.19it/s, batch_loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 37 Loss 1.2698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|██████████| 104/104 [00:06<00:00, 16.37it/s, batch_loss=1.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 38 Loss 1.2362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 104/104 [00:06<00:00, 15.94it/s, batch_loss=1.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 39 Loss 1.2112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 104/104 [00:06<00:00, 16.44it/s, batch_loss=0.951]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 40 Loss 1.1784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 104/104 [00:06<00:00, 16.05it/s, batch_loss=0.956]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 41 Loss 1.1507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 104/104 [00:06<00:00, 16.06it/s, batch_loss=0.707]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 42 Loss 1.1286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 104/104 [00:06<00:00, 15.93it/s, batch_loss=0.845]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 43 Loss 1.0938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 104/104 [00:06<00:00, 16.24it/s, batch_loss=0.892]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 44 Loss 1.0777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 104/104 [00:06<00:00, 16.09it/s, batch_loss=1.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 45 Loss 1.0488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 104/104 [00:06<00:00, 16.45it/s, batch_loss=0.921]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 46 Loss 1.0210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 104/104 [00:06<00:00, 16.14it/s, batch_loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 47 Loss 0.9957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 104/104 [00:06<00:00, 16.19it/s, batch_loss=0.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 48 Loss 0.9714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 104/104 [00:06<00:00, 15.99it/s, batch_loss=0.789]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 49 Loss 0.9480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 104/104 [00:06<00:00, 16.13it/s, batch_loss=0.992]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 50 Loss 0.9276\n",
            "ENG: Borderline cardiomegaly. Midline sternotomy noted.\n",
            "HIN: स्टर्नोटॉमी नोट किया गया।सिवनी स्टर्नोटॉमी के बाद कार्डियोमेगाली नोट किया गया है।दोनों फेफड़ों की स्थिति।स्थिर स्टर्नोटॉमी नोट किया गया।\n",
            "\n",
            "ENG: The cardiac silhouette and mediastinum size are within normal limits.\n",
            "HIN: हृदय सिल्हूट और मीडियास्टिनम सामान्य सीमा के भीतर हैं।कोई तीव्र हड्डी संबंधी असामान्यताएं नहीं हैं।\n",
            "\n",
            "Avg sentence BLEU (sample): 0.6437904150165957\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-e_QV_l8b19D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}